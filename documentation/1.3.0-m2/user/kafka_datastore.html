

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Kafka Data Store &mdash; GeoMesa 1.3.0-m2 Manuals</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme_custom.css" type="text/css" />
  

  

  
    <link rel="top" title="GeoMesa 1.3.0-m2 Manuals" href="../index.html"/>
        <link rel="up" title="User Manual" href="index.html"/>
        <link rel="next" title="HBase/Bigtable Data Stores" href="hbase_datastore.html"/>
        <link rel="prev" title="Accumulo Data Store" href="accumulo_datastore.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> GeoMesa
          

          
          </a>

          
            
            
              <div class="version">
                1.3.0-m2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">User Manual</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html">Architecture Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation_and_configuration.html">Installation and Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="datastores.html">GeoMesa Data Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="accumulo_datastore.html">Accumulo Data Store</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Kafka Data Store</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage-configuration">Usage/Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-producers">Data Producers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-consumers">Data Consumers</a></li>
<li class="toctree-l3"><a class="reference internal" href="#live-mode">Live Mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#replay-mode">Replay Mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-the-kafka-data-store-in-geoserver">Using the Kafka Data Store in GeoServer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#command-line-tools">Command Line Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hbase_datastore.html">HBase/Bigtable Data Stores</a></li>
<li class="toctree-l2"><a class="reference internal" href="cassandra_datastore.html">Cassandra Data Store</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules.html">Modules and Libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="geoserver.html">GeoMesa GeoServer Plugins</a></li>
<li class="toctree-l2"><a class="reference internal" href="spark.html">GeoMesa Spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="commandline_tools.html">Command Line Tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="data_management.html">Data Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#appendix">Appendix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index.html">Tutorials</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">GeoMesa</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
          <li><a href="index.html">User Manual</a> &raquo;</li>
      
    <li>Kafka Data Store</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/user/kafka_datastore.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="kafka-data-store">
<h1>Kafka Data Store<a class="headerlink" href="#kafka-data-store" title="Permalink to this headline">¶</a></h1>
<p>The GeoMesa Kafka Data Store is found in <code class="docutils literal"><span class="pre">geomesa-kafka/geomesa-kafka-datastore/geomesa-kafka-$KAFKAVERSION-datastore/</span></code> in the source
distribution.</p>
<p>The <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> is an implementation of the GeoTools
<code class="docutils literal"><span class="pre">DataStore</span></code> interface that is backed by Apache Kafka. The
implementation supports the ability for feature producers to instantiate
a <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> in <em>producer</em> mode to persist data into the data
store and for consumers to instantiate a <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> in
<em>consumer</em> mode to read data from the data store. The producer and
consumer data stores can be run on separate servers. The only
requirement is that they can connect to the same instance of Apache
Kafka.</p>
<p>A <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> in consumer mode supports two types of
<code class="docutils literal"><span class="pre">SimpleFeatureSource</span></code>&#8216;s: <em>live</em> and <em>replay</em>. A Kafka Consumer Feature
Source operating in <em>live</em> mode continually pulls data from the end of
the message queue (e.g. latest time) and always represents the latest
state of the simple features. A Kafka Consumer Feature Source operating
in <em>replay</em> mode will pull data from a specified time interval in the
past and can provide features as they existed at any point in time
within that interval.</p>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Use of the Kafka data store does not require server-side configuration,
however, a <code class="docutils literal"><span class="pre">geomesa-site.xml</span></code> configuration file is available for
setting system properties.</p>
<p>This file can be found at <code class="docutils literal"><span class="pre">conf/geomesa-site.xml</span></code> of the Kafka
distribution. The default settings for GeoMesa are stored in
<code class="docutils literal"><span class="pre">conf/geomesa-site.xml.template</span></code>. Do not modify this file directly as it
is never read, instead copy the desired configurations into
geomesa-site.xml.</p>
<p>By default command line parameters will take precedence over this
configuration file. If you wish a configuration item to always take
precedence, even over command line parameters change the <code class="docutils literal"><span class="pre">&lt;final&gt;</span></code>
tag to true.</p>
<p>By default configuration properties with empty values will not be
applied, you can change this by marking a property as final.</p>
</div>
<div class="section" id="usage-configuration">
<h2>Usage/Configuration<a class="headerlink" href="#usage-configuration" title="Permalink to this headline">¶</a></h2>
<p>To create a <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> there are two required properties, one
for the Apache Kafka connection, &#8220;brokers&#8221;, and one for the Apache
Zookeeper connection, &#8220;zookeepers&#8221;. An optional parameter, &#8220;zkPath&#8221; is
used to specify a path in Zookeeper under which schemas are stored. If
no &#8220;zkPath&#8221; is specified then a default path will be used. Another
optional parameter, &#8220;isProducer&#8221;, is used to create a <code class="docutils literal"><span class="pre">KafkaDataStore</span></code>
in <em>producer</em> or <em>consumer</em> mode. This parameter defaults to false, i.e.
by default a Kafka Consumer Data Store will be created. The same set of
configuration parameters, with the exception of &#8220;isProducer&#8221; must be
used to create both the Kafka Producer Data Store and the Kafka Consumer
Data Store.</p>
<p>After a <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> has been created, additional simple feature
type specific hints must be provided. These hints are stored in the user
data of the <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code>. Use the <code class="docutils literal"><span class="pre">KafkaDataStoreHelper</span></code> to
create a copy of your <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> with the hints added. Then
call <code class="docutils literal"><span class="pre">dataStore.createSchema(sft)</span></code> where <code class="docutils literal"><span class="pre">sft</span></code> is the
<code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> returned by the <code class="docutils literal"><span class="pre">KafkaDataStoreHelper</span></code>. This
must be done once per Simple Feature Type. The Simple Feature Type along
with hints are stored in Zookeeper so if <code class="docutils literal"><span class="pre">createSchema(sft)</span></code> is called
on the Kafka Data Store Producer it cannot be called on the Kafka
Consumer Data Store Consumer.</p>
</div>
<div class="section" id="data-producers">
<h2>Data Producers<a class="headerlink" href="#data-producers" title="Permalink to this headline">¶</a></h2>
<p>First, create the data store. For example:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">String</span> <span class="n">brokers</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">String</span> <span class="n">zookeepers</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">String</span> <span class="n">zkPath</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// build parameters map</span>
<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Serializable</span><span class="o">&gt;</span> <span class="n">params</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;&gt;();</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;brokers&quot;</span><span class="o">,</span> <span class="n">brokers</span><span class="o">);</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;zookeepers&quot;</span><span class="o">,</span> <span class="n">zookeepers</span><span class="o">);</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;isProducer&quot;</span><span class="o">,</span> <span class="n">Boolean</span><span class="o">.</span><span class="na">TRUE</span><span class="o">);</span>

<span class="c1">// optional</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;zkPath&quot;</span><span class="o">,</span> <span class="n">zkPath</span><span class="o">);</span>

<span class="c1">// create the data store</span>
<span class="n">KafkaDataStoreFactory</span> <span class="n">factory</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaDataStoreFactory</span><span class="o">();</span>
<span class="n">DataStore</span> <span class="n">producerDs</span> <span class="o">=</span> <span class="n">factory</span><span class="o">.</span><span class="na">createDataStore</span><span class="o">(</span><span class="n">params</span><span class="o">);</span>
</pre></div>
</div>
<p>Next, create the schema. Each data store can have one or many schemas.
For example:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">SimpleFeatureType</span> <span class="n">sft</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">SimpleFeatureType</span> <span class="n">streamingSFT</span> <span class="o">=</span> <span class="n">KafkaDataStoreHelper</span><span class="o">.</span><span class="na">createStreamingSFT</span><span class="o">(</span><span class="n">sft</span><span class="o">,</span> <span class="n">zkPath</span><span class="o">);</span>
<span class="n">producerDs</span><span class="o">.</span><span class="na">createSchema</span><span class="o">(</span><span class="n">streamingSFT</span><span class="o">);</span>
</pre></div>
</div>
<p>The call to <code class="docutils literal"><span class="pre">KafkaDataStoreHelper.createSchema</span></code> creates a copy of the
<code class="docutils literal"><span class="pre">sft</span></code> with the required hint added. In this case the hint is the name
of the Kafka topic. The <code class="docutils literal"><span class="pre">zkPath</span></code> parameter is uses to make the Kafka
topic name unique to the <code class="docutils literal"><span class="pre">zkPath</span></code> used by the <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> so
that the same <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> can be used by multiple
<code class="docutils literal"><span class="pre">KafkaDataStore</span></code>s where each data store has a different <code class="docutils literal"><span class="pre">zkPath</span></code>.
Specifically, the resulting Kafka topic&#8217;s name will be zkPath-sftName
where the forward slashes in the <code class="docutils literal"><span class="pre">zkPath</span></code> are replaced by <code class="docutils literal"><span class="pre">-</span></code>.  e.g. creating a schema
with a <code class="docutils literal"><span class="pre">zkPath</span></code> of /geomesa/ds/kafka with an <code class="docutils literal"><span class="pre">sft</span></code> called example_sft will
create a Kafka topic called geomesa-ds-kafka-example_sft.</p>
<p>The <code class="docutils literal"><span class="pre">createSchema</span></code> method will throw an exception if the given
<code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> does not contain the required hint, i.e., if it
was not created by the <code class="docutils literal"><span class="pre">KafkaDataStoreHelper</span></code>.</p>
<p>Now, you can create or update simple features:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="c1">// the name of the simple feature type -  will be the same as sft.getTypeName();</span>
<span class="n">String</span> <span class="n">typeName</span> <span class="o">=</span> <span class="n">streamingSFT</span><span class="o">.</span><span class="na">getTypeName</span><span class="o">();</span>

<span class="n">FeatureWriter</span><span class="o">&lt;</span><span class="n">SimpleFeatureType</span><span class="o">,</span> <span class="n">SimpleFeature</span><span class="o">&gt;</span> <span class="n">fw</span> <span class="o">=</span>
        <span class="n">producerDs</span><span class="o">.</span><span class="na">getFeatureWriter</span><span class="o">(</span><span class="n">typeName</span><span class="o">,</span> <span class="kc">null</span><span class="o">,</span> <span class="n">Transaction</span><span class="o">.</span><span class="na">AUTO_COMMIT</span><span class="o">);</span>
<span class="n">SimpleFeature</span> <span class="n">sf</span> <span class="o">=</span> <span class="n">fw</span><span class="o">.</span><span class="na">next</span><span class="o">();</span>
<span class="c1">// set properties on sf</span>
<span class="n">fw</span><span class="o">.</span><span class="na">write</span><span class="o">();</span>
</pre></div>
</div>
<p>Delete simple features:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">SimpleFeatureStore</span> <span class="n">producerStore</span> <span class="o">=</span> <span class="o">(</span><span class="n">SimpleFeatureStore</span><span class="o">)</span> <span class="n">producerDs</span><span class="o">.</span><span class="na">getFeatureSource</span><span class="o">(</span><span class="n">typeName</span><span class="o">);</span>
<span class="n">FilterFactory2</span> <span class="n">ff</span> <span class="o">=</span> <span class="n">CommonFactoryFinder</span><span class="o">.</span><span class="na">getFilterFactory2</span><span class="o">();</span>

<span class="n">String</span> <span class="n">id</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">producerStore</span><span class="o">.</span><span class="na">removeFeatures</span><span class="o">(</span><span class="n">ff</span><span class="o">.</span><span class="na">id</span><span class="o">(</span><span class="n">ff</span><span class="o">.</span><span class="na">featureId</span><span class="o">(</span><span class="n">id</span><span class="o">)));</span>
</pre></div>
</div>
<p>And, clear (delete all) features:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">producerStore</span><span class="o">.</span><span class="na">removeFeatures</span><span class="o">(</span><span class="n">Filter</span><span class="o">.</span><span class="na">INCLUDE</span><span class="o">);</span>
</pre></div>
</div>
<p>Each operation that creates, modifies, deletes, or clears simple
features results in a message being sent to the Kafka topic.</p>
</div>
<div class="section" id="data-consumers">
<h2>Data Consumers<a class="headerlink" href="#data-consumers" title="Permalink to this headline">¶</a></h2>
<p>First, create the data store. For example:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">String</span> <span class="n">brokers</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">String</span> <span class="n">zookeepers</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">String</span> <span class="n">zkPath</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// build parameters map</span>
<span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Serializable</span><span class="o">&gt;</span> <span class="n">params</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;&gt;();</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;brokers&quot;</span><span class="o">,</span> <span class="n">brokers</span><span class="o">);</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;zookeepers&quot;</span><span class="o">,</span> <span class="n">zookeepers</span><span class="o">);</span>

<span class="c1">// optional - the default is false</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;isProducer&quot;</span><span class="o">,</span> <span class="n">Boolean</span><span class="o">.</span><span class="na">FALSE</span><span class="o">);</span>

<span class="c1">// optional</span>
<span class="n">params</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">&quot;zkPath&quot;</span><span class="o">,</span> <span class="n">zkPath</span><span class="o">);</span>

<span class="c1">// create the data store</span>
<span class="n">KafkaDataStoreFactory</span> <span class="n">factory</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KafkaDataStoreFactory</span><span class="o">();</span>
<span class="n">DataStore</span> <span class="n">consumerDs</span> <span class="o">=</span> <span class="n">factory</span><span class="o">.</span><span class="na">createDataStore</span><span class="o">(</span><span class="n">params</span><span class="o">);</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">brokers</span></code>, <code class="docutils literal"><span class="pre">zookeepers</span></code>, and <code class="docutils literal"><span class="pre">zkPath</span></code> parameters must be
consistent with the values used to create the Kafka Data Store Producer.</p>
<p>Because <code class="docutils literal"><span class="pre">createSchema</span></code> was called on the Kafka Data Store Producer, it
does not need to be called on the Consumer. Calling <code class="docutils literal"><span class="pre">createSchema</span></code>
with a <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> that has already been created will result
in an exception being thrown. Note that all <code class="docutils literal"><span class="pre">SimpleFeature</span></code>s
returned by the Kafka Data Store consumer will have a
<code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> equal to the <code class="docutils literal"><span class="pre">streamingSFT</span></code> created when setting
up the producer, i.e. the <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> will include the hint
added by <code class="docutils literal"><span class="pre">KafkaDataStoreHelper.createStreamingSFT</span></code>.</p>
<p>Now that the Kafka Data Store Consumer has been created it can be
queried in either <em>live</em> or <em>replay</em> mode.</p>
</div>
<div class="section" id="live-mode">
<h2>Live Mode<a class="headerlink" href="#live-mode" title="Permalink to this headline">¶</a></h2>
<p>Live mode is the default and requires no extra setup. In this mode the
<code class="docutils literal"><span class="pre">SimpleFeatureSource</span></code> contains the current state of the
<code class="docutils literal"><span class="pre">KafkaDataStore</span></code>. As <code class="docutils literal"><span class="pre">SimpleFeatures</span></code> are created, modified,
deleted, or cleared by the Kafka Data Store Producer, the current state
is updated. All queries to the <code class="docutils literal"><span class="pre">SimpleFeatureSource</span></code> are queries
against the current state. For example:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">String</span> <span class="n">typeName</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">SimpleFeatureSource</span> <span class="n">liveFeatureSource</span> <span class="o">=</span> <span class="n">consumerDs</span><span class="o">.</span><span class="na">getFeatureSource</span><span class="o">(</span><span class="n">typeName</span><span class="o">);</span>

<span class="n">Filter</span> <span class="n">filter</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">liveFeatureSource</span><span class="o">.</span><span class="na">getFeatures</span><span class="o">(</span><span class="n">filter</span><span class="o">);</span>
</pre></div>
</div>
<p>It is also possible to provide a CQL filter to the getFeatureSource method call which will ensure
the resulting <code class="docutils literal"><span class="pre">FeatureSource</span></code> only contains certain records. Providing a filter to reduce the number of
returned records will provide a performance boost when using the featureSource.</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">String</span> <span class="n">typeName</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">SimpleFeatureSource</span> <span class="n">liveFeatureSource</span> <span class="o">=</span> <span class="n">consumerDs</span><span class="o">.</span><span class="na">getFeatureSource</span><span class="o">(</span><span class="n">typeName</span><span class="o">,</span> <span class="n">filter</span><span class="o">);</span>
</pre></div>
</div>
</div>
<div class="section" id="replay-mode">
<h2>Replay Mode<a class="headerlink" href="#replay-mode" title="Permalink to this headline">¶</a></h2>
<p>Replay mode allows the a user to query the <code class="docutils literal"><span class="pre">KafkaDataStore</span></code> as it
existed at any point in the past. Queries against a Kafka Replay Simple
Feature source specify a historical time to query and only the set and
version of <code class="docutils literal"><span class="pre">SimpleFeature</span></code>s that existed at that point in time will
be used to answer the query.</p>
<p>In order to use Replay mode some additional hints are required: the
start and end times of the replay window and a read behind duration:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">Instant</span> <span class="n">replayStart</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">Instant</span> <span class="n">replayEnd</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">Duration</span> <span class="n">readBehind</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">ReplayConfig</span> <span class="n">replayConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ReplayConfig</span><span class="o">(</span><span class="n">replayStart</span><span class="o">,</span> <span class="n">replayEnd</span><span class="o">,</span> <span class="n">readBehind</span><span class="o">);</span>
</pre></div>
</div>
<p>The replay window is simply an optimization that allows the Kafka Replay
Feature Source to load, at initialization time, all state changes that
occur within the window. Any query for a time outside of the window will
return no results even if features existed at that time.</p>
<p>The read behind is the amount of time used to rebuild state. For
example, if <code class="docutils literal"><span class="pre">readBehind</span> <span class="pre">=</span> <span class="pre">5s</span></code> then for a query requesting state at
<code class="docutils literal"><span class="pre">time</span> <span class="pre">=</span> <span class="pre">t</span></code> all state changes that occurred between <code class="docutils literal"><span class="pre">t</span> <span class="pre">-</span> <span class="pre">5s</span></code> and
<code class="docutils literal"><span class="pre">t</span></code> will be used to build the state at time <code class="docutils literal"><span class="pre">t</span></code> which will then be
used to answer the query. Selecting an appropriate read behind requires
an understanding of the producer. The expected uses case is a producer
that updates every simple feature, even if it hasn&#8217;t changed, at a
regular interval. For example, if the producer is updating every <code class="docutils literal"><span class="pre">x</span></code>
seconds then a read behind of <code class="docutils literal"><span class="pre">x</span> <span class="pre">+</span> <span class="pre">1s</span></code> might be appropriate.</p>
<p>During initialization of the Kafka Replay Feature Source all state
changes from <code class="docutils literal"><span class="pre">replayStart</span> <span class="pre">-</span> <span class="pre">readBehind</span></code> to <code class="docutils literal"><span class="pre">replayEnd</span></code> will be read
and cached. As the size of the replay window and read behind increases
so does the amount of data that must be read and cashed. So, both the
size of the window and the read behind should be kept as small as
possible.</p>
<p>After creating the <code class="docutils literal"><span class="pre">ReplayConfig</span></code> pass it, along with the
<code class="docutils literal"><span class="pre">streamingSFT</span></code> to the <code class="docutils literal"><span class="pre">KafkaDataStoreHelper</span></code>:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">SimpleFeatureType</span> <span class="n">streamingSFT</span> <span class="o">=</span> <span class="n">consumerDs</span><span class="o">.</span><span class="na">getSchema</span><span class="o">(</span><span class="n">typeName</span><span class="o">);</span>
<span class="n">SimpleFeatureType</span> <span class="n">replaySFT</span> <span class="o">=</span> <span class="n">KafkaDataStoreHelper</span><span class="o">.</span><span class="na">createReplaySFT</span><span class="o">(</span><span class="n">streamingSFT</span><span class="o">,</span> <span class="n">replayConfig</span><span class="o">);</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">streamingSFT</span></code> passed to <code class="docutils literal"><span class="pre">createReplaySFT</span></code> must contain the
hints added by <code class="docutils literal"><span class="pre">KafkaDataStoreHelper.createStreamingSFT</span></code>. The easiest
way to ensure this is to call <code class="docutils literal"><span class="pre">consumerDs.getSchema(typeName)</span></code>. The
<code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> returned by <code class="docutils literal"><span class="pre">createReplaySFT</span></code> will contain the
hint added by <code class="docutils literal"><span class="pre">createStreamingSFT</span></code> as well as a a hint containing the
<code class="docutils literal"><span class="pre">ReplayConfig</span></code>. Additionally the <code class="docutils literal"><span class="pre">replaySFT</span></code> will have a different
name then then <code class="docutils literal"><span class="pre">streamingSFT</span></code>. This is to differentiate <em>live</em> and
<em>replay</em> <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code>s. The <code class="docutils literal"><span class="pre">replaySFT</span></code> will also contain
an additional attribute, <code class="docutils literal"><span class="pre">KafkaLogTime</span></code>, of type <code class="docutils literal"><span class="pre">java.util.Date</span></code>
which represents the historical query time.</p>
<p>After creating the <code class="docutils literal"><span class="pre">replaySFT</span></code> the Kafka Replay Feature Source may be
created:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">consumerDs</span><span class="o">.</span><span class="na">createSchema</span><span class="o">(</span><span class="n">replaySFT</span><span class="o">);</span>

<span class="n">String</span> <span class="n">replayTimeName</span> <span class="o">=</span> <span class="n">replaySFT</span><span class="o">.</span><span class="na">getTypeName</span><span class="o">();</span>
<span class="n">SimpleFeatureSource</span> <span class="n">replayFeatureSource</span> <span class="o">=</span> <span class="n">consumerDs</span><span class="o">.</span><span class="na">getFeatureSource</span><span class="o">(</span><span class="n">replayTimeName</span><span class="o">);</span>
</pre></div>
</div>
<p>The call to <code class="docutils literal"><span class="pre">createSchema</span></code> is required because the <code class="docutils literal"><span class="pre">replaySFT</span></code> is a
new <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code>.</p>
<p>Finally the Kafka Replay Consumer Feature Source can be queried:</p>
<div class="highlight-java"><div class="highlight"><pre><span></span><span class="n">Instant</span> <span class="n">historicalTime</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">Filter</span> <span class="n">timeFilter</span> <span class="o">=</span> <span class="n">ff</span><span class="o">.</span><span class="na">and</span><span class="o">(</span><span class="n">filter</span><span class="o">,</span> <span class="n">ReplayTimeHelper</span><span class="o">.</span><span class="na">toFilter</span><span class="o">(</span><span class="n">historicalTime</span><span class="o">));</span>

<span class="n">replayFeatureSource</span><span class="o">.</span><span class="na">getFeatures</span><span class="o">(</span><span class="n">timeFilter</span><span class="o">);</span>
</pre></div>
</div>
</div>
<div class="section" id="using-the-kafka-data-store-in-geoserver">
<h2>Using the Kafka Data Store in GeoServer<a class="headerlink" href="#using-the-kafka-data-store-in-geoserver" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference internal" href="geoserver.html"><span class="doc">GeoMesa GeoServer Plugins</span></a>.</p>
</div>
<div class="section" id="command-line-tools">
<h2>Command Line Tools<a class="headerlink" href="#command-line-tools" title="Permalink to this headline">¶</a></h2>
<p>The KafkaGeoMessageFormatter, part of geomesa-kafka-datastore, may be
used with the <code class="docutils literal"><span class="pre">kafka-console-consumer</span></code>, part of Apache Kafka. In order
to use this formatter call the kafka-console consumer with these
additional arguments:</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Replace <code class="docutils literal"><span class="pre">$KAFKAVERSION</span></code> below with the appropriate version number for your environment: 08, 09, or 10.
e.g. <code class="docutils literal"><span class="pre">org.locationtech.geomesa.kafka08.KafkaGeoMessageFormatter</span></code></p>
</div>
<div class="highlight-bash"><div class="highlight"><pre><span></span>--formatter org.locationtech.geomesa.kafka<span class="nv">$KAFKAVERSION</span>.KafkaGeoMessageFormatter
--property sft.name<span class="o">={</span>sftName<span class="o">}</span>
--property sft.spec<span class="o">={</span>sftSpec<span class="o">}</span>
</pre></div>
</div>
<p>In order to pass the spec via a command argument all <code class="docutils literal"><span class="pre">%</span></code> characters
must be replaced by <code class="docutils literal"><span class="pre">%37</span></code> and all <code class="docutils literal"><span class="pre">=</span></code> characters must be replaced by
<code class="docutils literal"><span class="pre">%61</span></code>.</p>
<p>A slightly easier to use but slightly less flexible alternative is to
use the <code class="docutils literal"><span class="pre">KafkaDataStoreLogViewer</span></code> instead of the
<code class="docutils literal"><span class="pre">kafka-console-consumer</span></code>. To use the <code class="docutils literal"><span class="pre">KafkaDataStoreLogViewer</span></code> first
copy the geomesa-kafka-geoserver-plugin.jar to $KAFKA_HOME/libs. Then
create a copy of $KAFKA_HOME/bin/kafka-console-consumer.sh called
&#8220;kafka-ds-log-viewer&#8221; and in the copy replace the classname in the exec
command at the end of the script with
<code class="docutils literal"><span class="pre">org.locationtech.geomesa.kafka$KAFKAVERSION.KafkaDataStoreLogViewer</span></code>.</p>
<p>The <code class="docutils literal"><span class="pre">KafkaDataStoreLogViewer</span></code> requires three arguments:
<code class="docutils literal"><span class="pre">--zookeeper</span></code>, <code class="docutils literal"><span class="pre">--zkPath</span></code>, and <code class="docutils literal"><span class="pre">--sftName</span></code>. It also supports an
optional argument <code class="docutils literal"><span class="pre">--from</span></code> which accepts values <code class="docutils literal"><span class="pre">oldest</span></code> and
<code class="docutils literal"><span class="pre">newest</span></code>. <code class="docutils literal"><span class="pre">oldest</span></code> is equivalent to specifying <code class="docutils literal"><span class="pre">--from-beginning</span></code>
when using the <code class="docutils literal"><span class="pre">kafka-console-consumer</span></code> and <code class="docutils literal"><span class="pre">newest</span></code> is equivalent
to not specifying <code class="docutils literal"><span class="pre">--from-beginning</span></code>.</p>
<p>For example:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ kafka-ds-log-viewer --zookeeper <span class="o">{</span>zookeeper<span class="o">}</span> --zkPath <span class="o">{</span>zkPath<span class="o">}</span> --sftName <span class="o">{</span>sftName<span class="o">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">KafkaDataStoreLogViewer</span></code> loads the <code class="docutils literal"><span class="pre">SimpleFeatureType</span></code> from
Zookeeper so it does not need to be passed via the command line.</p>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="hbase_datastore.html" class="btn btn-neutral float-right" title="HBase/Bigtable Data Stores" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="accumulo_datastore.html" class="btn btn-neutral" title="Accumulo Data Store" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2013-2016 Commonwealth Computer Research, Inc.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.3.0-m2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>